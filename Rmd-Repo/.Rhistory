auto.arima(roll_apple) %>% forecast(50) %>% plot(col = "green")
auto.arima(AAPL$AAPL.Adjusted) %>% forecast(50) %>% lines(col = "red")
auto.arima(AAPL$AAPL.Adjusted) %>% forecast(50) %>% lines()
auto.arima(AAPL$AAPL.Adjusted) %>% forecast(50) %>% lines(col = "red")
auto.arima(AAPL$AAPL.Adjusted) %>% forecast(50) %>% plot(col = "red")
#q1
c = c(-1,4)
A = matrix(c(-10,5,1,0,20,10,0,1),4,2)
A
b = c(22,49,5,5)
dir = rep("<=",4)
sol = lp("max",c,A,dir,b, all.int = T)
sol$solution
library(lpSolve)
A = matrix(c(-10,5,1,0,20,10,0,1),4,2)
A
b = c(22,49,5,5)
dir = rep("<=",4)
sol = lp("max",c,A,dir,b, all.int = T)
sol$solution
#left branch
b1 = c(22,49,3,5)
sol = lp("max",c,A,dir,b1)
sol$solution
b3 = c(22,49,3,2)
sol = lp("max",c,A,dir,b3)
sol$solution
b7 = c(22,49,1,2)
sol = lp("max",c,A,dir,b7)
sol$solution
b8 = c(22,49,2,2)
sol = lp("max",c,A,c("<=","<=","=","<="),b8)
sol$solution
b5 = c(22,49,3,3)
sol = lp("max",c,A,c("<=","<=","<=",">="),b5)
sol$solution
#right branch
b2 = c(22,49,4,5)
sol = lp("max",c,A,c("<=","<=",">=","<="),b2)
sol$solution
b4 = c(22,49,4,2)
sol = lp("max",c,A,dir,b4)
sol$solution
b9 = c(22,49,1,2)
sol = lp("max",c,A,dir,b9)
sol$solution
b10 = c(22,49,2,2)
sol = lp("max",c,A,c("<=","<=","=","<="),b10)
sol$solution
b6 = c(22,49,4,3)
sol = lp("max",c,A,c("<=","<=","<=",">="),b6)
sol$solution
#q2
c2 = c(9,5,6,4)
bq2 = c(11,1,1)
A = matrix(0,3,4)
A[1,] = c(6,3,5,2)
A[2,] = c(1,1,0,0)
A[3,] = c(0,0,1,1)
A
dir = c("<=",">=","<=")
solution = lp("max",c,A,dir,bq2, all.bin = T)
solution$solution
#q3
Amat = matrix(0,12,12)
Amat
Amat
Amat = diag(12)
Amat
Amat[1,3] = 1
Amat[1,5] = 1
Amat[1,7] = 1
Amat
Amat[1,8] = 1
Amat[1,9] = 1
Amat
Amat[2,8:9] = c(1,1)
Amat
Amat[3,7:9] = c(1,1,1)
Amat
Amat[4,10] = 1
Amat
Amat[5,7] =1
Amat[6,10:11] = rep(1,2)
Amat
Amat[8,9] =1
Amat[10,11:12] = rep(1,2)
Amat[11,12] =1
Amat
c = rep(1,12)
obj = rep(1,12)
dir = rep("<=",12)
sol = lp("min",c,Amat,dir,c,all,bin =T)
sol = lp("min",c,Amat,dir,rep(1,12),all,bin =T)
sol = lp("min",c,Amat,dir,rep(1,12),all.bin =T)
sol$solution
sol = lp("max",c,Amat,dir,rep(1,12),all.bin =T)
sol$solution
Amat[3,1] = 1
Amat[3,3] =1
Amat[5,1] = 1
Amat[7,1] =1
Amat[7,3] = 1
Amat[7,5] =1
Amat[8,1:3] = rep(1,3)
Amat[9,1:3] = rep(1,3)
Amat[9,8] = 1
Amat[10,4] =1
Amat[10,6] =1
Amat[11,6] =1
Amat[11,10] =1
Amat[12,10:11] =1
Amat
c = rep(1,12)
obj = rep(1,12)
dir = rep("<=",12)
sol = lp("max",c,Amat,dir,rep(1,12),all.bin =T)
sol$solution
dir = rep("=",12)
sol = lp("max",c,Amat,dir,rep(1,12),all.bin =T)
sol$solution
#q4
25*233+37*148+54*106
17025/120
142*3
mat = matrix(0,4,426)
mat
head(mat)
#q4
mat = c(25,37,54)
c = c(25,37,54)
sol = lp("max",c,mat,"<=",rep(1,3),all.int = T)
sol$solution
#q4
mat = c(25,37,54)
c = c(25,37,54)
sol = lp("max",c,mat,"<=",rep(1,3),all.int = T)
sol$solution
sol = lp("max",c,mat,"<=",120,all.int = T)
sol$solution
sol$solution
b = c(120)
sol = lp("max",c,mat,"<=",b,all.int = T)
sol$solution
mat = c(25,37,54)
c = c(25,37,54)
b = c(120)
sol = lp("max",c,mat,"<=",b,all.int = T)
sol$solution
mat
c = c(-25,-37,-54)
b = c(120)
sol = lp("max",c,mat,"<=",b,all.int = T)
sol$solution
sol = lp("min",c,mat,"<=",b,all.int = T)
sol$solution
sol$objval
c = c(25,37,54)
sol = lp("min",c,mat,"<=",b,all.int = T)
sol$solution
sol$objval
sol = lp("max",c,mat,"<=",b,all.int = T)
sol$solution
sol$objval
A = matrix(0,4,500)
A
A[1,] =
25*233+37*148+54*106
A[1,] =
25*233+37*148+54*106
25*233+37*148+54*106
17025/120
A = matrix(0,4,142)
A
142/3
142*3
A = matrix(0,4,426)
A[1,] = rep(c(25,37,54),142)
A
A[2,] = rep(c(1,0,0),142)
A[3,] = rep(c(0,1,0),142)
A[4,] = rep(c(0,0,1),142)
A
A[,1]
120*142
b = c(17040,233,148,106)
dir = c("<=","=","=","=")
obj = rep(1,426)
sol = lp("max",obj,A,dir,b, all.int = T)
sol$solution
library(lpsolve)
library(lpSolve)
pmi <- read.csv("ISM-MAN_PMI_cl.csv")
setwd("C:/Users/arunk/Downloads")
pmi <- read.csv("ISM-MAN_PMI_cl.csv")
library(quantmod)
pmi <- as.xts(pmi[,2:ncol(pmi)], pmi$Date)
pmi <- as.xts(pmi[,2:ncol(pmi)], order.by = pmi$Date)
pmi <- read.csv("ISM-MAN_PMI_cl.csv")
library(quantmod)
pmi <- as.xts(pmi[,2:ncol(pmi)], order.by = pmi$Date)
pmi <- as.xts(pmi[,2:ncol(pmi)], order.by = as.Date(pmi$Date))
pmi <- as.xts(pmi[,2:ncol(pmi)], order.by = as.Date(pmi$Date), format = "%m/%d/%Y")
pmi <- as.xts(pmi[,2:ncol(pmi)], order.by = as.Date(pmi$Date), format = "%m/%d/%Y")
pmi <- as.xts(pmi[,2:ncol(pmi)], order.by = as.Date(pmi$Date, format = "%m/%d/%Y")
pmi <- as.xts(pmi[,2:ncol(pmi)], order.by = as.Date(pmi$Date, format = "%m/%d/%Y"))
pmi <- as.xts(pmi[,2:ncol(pmi)], order.by = as.Date(pmi$Date, format = "%m/%d/%Y"))
pmi <- as.xts(pmi[,2:ncol(pmi)], order.by = as.Date(pmi$Date, format = "%m/%d/%Y"))
View(pmi)
pmi <- pmi[1:241,]
pmi <- as.xts(pmi[,2:ncol(pmi)], order.by = as.Date(pmi$Date, format = "%m/%d/%Y"))
head(pmi)
pmi[,3:ncol(pmi)] <- NULL
pmi[,3:ncol(pmi)] <- rep(NULL)
pmi$X <- NULL
pmi$X.1 <- NULL
pmi$X.2 <-NULL
pmi$X.3 <- NULL
pmi$X.4 <- NULL
pmi$X.5 <- NULL
t <- seq(start(pmi), end(pmi), by = 1)
t_ts <- as.xts(rep(NA,length(t)), t)
View(t_ts)
View(pmi)
pmi <- read.csv("ISM-MAN_PMI_cl.csv")
library(quantmod)
pmi <- pmi[1:241,]
pmi <- as.xts(pmi[,2:ncol(pmi)], order.by = as.Date(pmi$Date, format = "%m/%d/%y"))
pmi$X <- NULL
pmi$X.1 <- NULL
pmi$X.2 <-NULL
pmi$X.3 <- NULL
pmi$X.4 <- NULL
pmi$X.5 <- NULL
t <- seq(start(pmi), end(pmi), by = 1)
t <- seq(start(pmi), end(pmi), by = 1)
View(pmi)
pmi <- read.csv("ISM-MAN_PMI_cl.csv")
pmi <- pmi[1:241,]
pmi <- as.xts(pmi[,2:ncol(pmi)], order.by = as.Date(pmi$Date, format = "%m/%d/%y"))
pmi$X <- NULL
pmi$X.1 <- NULL
pmi$X.2 <-NULL
pmi$X.3 <- NULL
pmi$X.4 <- NULL
pmi$X.5 <- NULL
t <- seq(start(pmi), end(pmi), by = 1)
t_ts <- as.xts(rep(NA,length(t)), t)
t_pmi <- merge.xts(t_ts, pmi)
View(t_pmi)
t_pmi$t_ts <- NULL
t_pmi <- na.locf(t_pmi)
t_pmi <- na.locf0(t_pmi, fromLast = T)
write.zoo(t_pmi, file = "filled_pmi.csv", sep = ",")
knitr::opts_chunk$set(echo  =  TRUE)
ggplot(msleep)
library(msleep)
ggplot(msleep)
library(ggplot2)
library(ggplot2)
ggplot(msleep)
ggplot(msleep)
library(ggplot2)
ggplot(msleep)
ggplot(msleep, aes(x = size)) + geom_bar()
msleep <- msleep
RColorBrewer::display.brewer.all()
msleep1<-msleep[!is.na(msleep$brainwt),]
ggplot(msleep1, aes(sleep_total,sleep_rem))+
geom_point(aes(color=log10(brainwt)), size=3)
ggplot(msleep1, aes(sleep_total,sleep_rem))+
geom_point(aes(color=log10(brainwt)), size=3)+
scale_color_gradient(low="yellow", high="red")
msleep1<-msleep[!is.na(msleep$brainwt),]
ggplot(msleep1, aes(sleep_total,sleep_rem))+
geom_point(aes(color=log10(brainwt)), size=3)
ggplot(msleep1, aes(sleep_total,sleep_rem))+
geom_point(aes(color=log10(brainwt)), size=3)+
scale_color_gradient(low="yellow", high="red")
ggplot(msleep1, aes(sleep_total, sleep_rem))+geom_density2d()
data  <-  data.frame(roll = 1:10,  prob = 1/10)
ggplot(data,  aes(roll, prob)) + geom_bar(stat = "identity") +
scale_x_continuous(breaks = 1:10)
data <- data.frame(roll = 1:100,  prob = 1/100)
ggplot(data,  aes(roll, prob)) + geom_bar(stat = "identity") +
scale_x_continuous(breaks=1:100,minor_breaks = NULL)
data <- data.frame(roll = 1:500,  prob = 1/1000)
ggplot(data,  aes(roll, prob))  +  geom_bar(stat = "identity") +
scale_x_continuous(breaks=1:1000, minor_breaks = NULL, labels=NULL)
data  <-  data.frame(roll = 1:10,  prob = 1/10)
data
sample((1:6),5)
plot(sample((1:6),5))
ggplot(sample((1:6),5)) + geom_point()
ggplot(as.dataframe(sample((1:6),5))) + geom_point()
ggplot(as.data.frame(sample((1:6),5))) + geom_point()
sample(1:6,4, replace = T)
sample(1:6,400, replace = T)
ggplot()+geom_bar(rolls, aes(x=rolls))
sample(1:6,400, replace = T)
sample(1:6,400, replace = T)
ggplot()+geom_bar(rolls, aes(x=rolls))
rolls <- sample(1:6,400, replace = T)
ggplot()+geom_bar(rolls, aes(x=rolls))
ggplot( aes(x=rolls))+geom_bar(rolls)
data  <-  data.frame(roll = 1:10,  prob = 1/10)
ggplot(data,  aes(roll, prob)) + geom_bar(stat = "identity") +
scale_x_continuous(breaks = 1:10)
data <- data.frame(roll = 1:100,  prob = 1/100)
ggplot(data,  aes(roll, prob)) + geom_bar(stat = "identity") +
scale_x_continuous(breaks=1:100,minor_breaks = NULL)
data <- data.frame(roll = 1:100,  prob = 1/100)
data <- data.frame(roll = 1:100,  prob = 1/100)
data  <-  data.frame(roll = 1:10,  prob = 1/10)
data  <-  data.frame(roll = 1:10,  prob = 1/10)
ggplot(data,  aes(roll, prob)) + geom_bar(stat = "identity") +
scale_x_continuous(breaks = 1:10)
data <- data.frame(roll = 1:100,  prob = 1/100)
ggplot(data,  aes(roll, prob)) + geom_bar(stat = "identity") +
scale_x_continuous(breaks=1:100,minor_breaks = NULL)
setwd("~/GitHub/arun-krishnaraj.github.io/Rmd-Repo")
setwd("~/GitHub/arun-krishnaraj.github.io/Rmd-Repo")
lynxhare = read.table("lynxhare.tsv",
sep="\t", row.names=NULL, header=TRUE)
lynxhare = read.table("lynxhare.tsv",
sep="\t", row.names=NULL, header=TRUE)
install.packages("tidyverse")
install.packages("ggridges")
library(tidyverse) #IMPORTANT: YOU MUST RUN THIS FIRST IN JUST ABOUT EVERY ASSIGNMENT!
data(txhousing)
#glimpse() is a dplyr function similar to str() and head()
glimpse(txhousing)
#create a column called state and put TX in every cell
txhousing %>% mutate(state="TX")
#create an average home price variable
txhousing %>% mutate(average=volume/sales)
head(txhousing) #where is our new variable? We didn't save it!
txhousing %>% mutate(`sales_pctile`=ntile(sales,100))
txhousing %>% mutate(inventory4tile = ntile(inventory,4))
txhousing = txhousing %>% mutate(inventory4tile = ntile(inventory,4))
#recode numeric data to character data (ascending order)
txhousing <- txhousing %>%
mutate(month2 = recode(month,"Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"))
head(txhousing)
#recode character data to character data
txhousing %>% mutate(month2=recode(month2, Jan="Enero", Feb="Febrero"))
txhousing %>%
filter(city == "Fort Worth") %>%
mutate(city = str_replace(city, "Fort", "Ft"))
txhousing %>%
mutate(city= tolower(city))
txhousing %>%
filter(city=="Austin") %>%
arrange(year, month) %>% #make sure it's in chronological order
mutate(pct_change = (sales-lag(sales)) / lag(sales)) #compute percent change from previous month
Use case_when() to create categories from a numeric variable
Here, we want a column that says "high" if listings are over 2000, "med" if between 500 and 2000, "low" otherwise.
Keeps you from having to daisychain ifelse statements
#could use a chain of ifelse, but this is confusing
txhousing%>%
mutate(listings_cat = ifelse(listings>2000, "high",
ifelse(listings<=2000 & 500<=listings, "med", "low")))
txhousing %>% mutate(logVolume=log10(volume)) %>% ggplot()+geom_histogram(aes(logVolume))
#create a new column with the average volume, bring it to the front
txhousing %>% mutate(meanvol=mean(volume)) %>% select(meanvol, everything())
#create a new column with the average volume, bring it to the front
txhousing %>% mutate(meanvol=mean(volume)) %>% select(meanvol, everything())
txhousing %>% mutate(meanvol=mean(volume, na.rm=T)) %>% select(meanvol, everything())
txhousing %>% summarize(mean(volume, na.rm=T))
txhousing %>% summarize(n()) #number of rows
txhousing %>% summarize(n_distinct(city)) #number of distinct cities
#can do more than one at once!
txhousing %>% summarize(mean(volume, na.rm=T), n(), n_distinct(city))
#can give them new names
txhousing %>% summarize(mean_vol = mean(volume, na.rm=T), n_rows=n(), n_cities= n_distinct(city))
txhousing %>% group_by(city) %>%
summarize(mean_vol=mean(volume,na.rm=T), sd_vol=sd(volume, na.rm=T))
txhousing %>% group_by(month2) %>% summarize(`average sales`=mean(sales,na.rm = T)) %>% ggplot(aes(month2, `average sales`))+
geom_bar(stat = "identity")
txhousing %>% group_by(year,month) %>% summarize(mean = mean(volume, na.rm = T), sd = sd(volume, na.rm=T))
txhousing %>% group_by(year,month) %>% summarize(mean = mean(volume, na.rm = T), sd = sd(volume, na.rm=T), n=n())
txhousing %>% group_by(year,month) %>% summarize(mean = mean(volume, na.rm = T), sd = sd(volume, na.rm=T), n=n()) %>% ggplot()+geom_bar(aes(month, mean), stat = "identity") +facet_wrap(~year)
txhousing %>% group_by(month2) %>% summarize(`average sales`=mean(sales,na.rm = T)) %>% ggplot(aes(month2, `average sales`))+
geom_bar(stat = "identity")
txhousing %>% group_by(year,month) %>% summarize(mean = mean(volume, na.rm = T), sd = sd(volume, na.rm=T), n=n(), se = sd/sqrt(n)) %>% ggplot()+geom_bar(aes(month, mean), stat = "identity") +facet_wrap(~year) + geom_errorbar(aes(y=mean,ymin=mean-se, ymax=mean+se))
txhousing %>% group_by(year,month) %>% summarize(mean = mean(volume, na.rm = T), sd = sd(volume, na.rm=T), n=n(), se = sd/sqrt(n)) %>% ggplot(aes(month, mean))+geom_bar(, stat = "identity") +facet_wrap(~year) + geom_errorbar(aes(y=mean,ymin=mean-se, ymax=mean+se))
txhousing %>% group_by(year,month) %>% summarize(mean = mean(volume, na.rm = T), sd = sd(volume, na.rm=T), n=n(), se = sd/sqrt(n)) %>% ggplot(aes(month, mean))+geom_bar(stat = "identity") +facet_wrap(~year) + geom_errorbar(aes(y=mean,ymin=mean-se, ymax=mean+se))
txhousing %>% ggplot(aes(month,volume)) + facet_wrap(~year) +
geom_bar(stat="summary", fun=mean) + geom_errorbar(stat="summary", fun.data=mean_se)
library(ggridges)
txhousing %>% filter(year==2000) %>% ggplot(aes(volume,y=month2)) +
geom_density_ridges(quantile_lines = TRUE, quantiles = 2) + scale_x_log10()
txhousing %>% ggplot(aes(volume,y=month2))+geom_density_ridges(quantile_lines = TRUE, quantiles = 2)+scale_x_log10()+facet_wrap(~year)
knitr::opts_chunk$set(echo = TRUE)
positionsAtStepT = function(walks, t){
unlist(lapply(walks, function(rw){rw[[t+1]]}))
}
positionsAtStepT(fixedStepWalks, 5)
knitr::opts_chunk$set(echo = TRUE)
fixedSizeStepper <- function(nSteps){
sample(c(-1, +1), nSteps, replace = TRUE)
}
uniformStepper <- function(nSteps){
sqrt(12) * (runif(nSteps) - 1/2)
}
randomWalk <- function(nSteps, stepper){
steps <- stepper(nSteps)
return(c(0, cumsum(steps)))
}
randomWalk(12, uniformStepper)
randomWalks <- function(nSteps, stepper = fixedSizeStepper, nWalks = 100000){
lapply(1:nWalks,function(i){randomWalk(nSteps, stepper)})
}
fixedStepWalks <- randomWalks(nSteps = 100, stepper = fixedSizeStepper)
unifWalks <- randomWalks(nSteps = 100, stepper = uniformStepper)
gaussianWalks <- randomWalks(nSteps = 100, stepper = rnorm)
positionsAtStepT(fixedStepWalks, 5)
positionsAtStepT(fixedStepWalks, )
positionsAtStepT = function(walks, t){
unlist(lapply(walks, function(rw){rw[[t+1]]}))
}
positionsAtStepT(fixedStepWalks, 5)
positionsAtStepT(unifWalks, 5)
class(positionsAtStepT(unifWalks, 5))
positionsAtStepT = function(walks, t){
(lapply(walks, function(rw){rw[[t+1]]}))
}
class(positionsAtStepT(unifWalks, 5))
plotData = lapply(c(1,2,5,10), function(nSteps){
rbind(
data.frame(stepper = "+/-1",
t = nSteps,
x = positionsAtStepT(fixedStepWalks, nSteps)),
data.frame(stepper = "uniform",
t = nSteps,
x = positionsAtStepT(unifWalks, nSteps)),
data.frame(stepper = "gaussian",
t = nSteps,
x = positionsAtStepT(gaussianWalks, nSteps))
)
})
plotData = lapply(c(1,2,5,10), function(nSteps){
rbind(
data.frame(stepper = "+/-1",
t = nSteps,
x = positionsAtStepT(fixedStepWalks, nSteps)),
data.frame(stepper = "uniform",
t = nSteps,
x = positionsAtStepT(unifWalks, nSteps)),
data.frame(stepper = "gaussian",
t = nSteps,
x = positionsAtStepT(gaussianWalks, nSteps))
)
})
length(c(1,2,5,10))
rbind(
data.frame(stepper = "+/-1",
t = nSteps,
x = positionsAtStepT(fixedStepWalks, nSteps)),
data.frame(stepper = "uniform",
t = nSteps,
x = positionsAtStepT(unifWalks, nSteps)),
data.frame(stepper = "gaussian",
t = nSteps,
x = positionsAtStepT(gaussianWalks, nSteps))
)
plotData = lapply(c(1,2,5,10), function(nSteps){
rbind(
data.frame(stepper = "+/-1",
t = nSteps,
x = positionsAtStepT(fixedStepWalks, nSteps)),
data.frame(stepper = "uniform",
t = nSteps,
x = positionsAtStepT(unifWalks, nSteps)),
data.frame(stepper = "gaussian",
t = nSteps,
x = positionsAtStepT(gaussianWalks, nSteps))
)
})
install.packages("nycflights13")
# install.packages("nycflights13")
library(nycflights13)
library(tidyverse)
flights<-flights
airlines<-airlines
glimpse(flights)
flights %>% summarize_all(function(x)sum(is.na(x)))
flights %>% summarize_all(function(x) sum(is.na(x)))
flights %>% filter(function(x) sum(is.na(x)))
flights %>% summarize_all(function(x) sum(is.na(x)))
flights %>% filter_all(!is.na())
flights %>% filter_all(!is.na)
flights %>% filter(!is.na(dep_time))
flights %>% filter(!is.na(year:month))
flights %>% filter(!is.na(year, month))
flights %>% filter(!is.na(year))
flights %>% filter(!is.na(dep_time), !is.na(dep_delay), !is.na(arr_time), !is.na(arr_delay),)
flights %>% filter(!is.na(dep_time), !is.na(dep_delay), !is.na(arr_time), !is.na(arr_delay)) -> flights1
flights1 %>% summarize_all(function(x) sum(is.na(x)))
flights1 %>% filter(air_time == max(air_time))
flights1 %>% filter(air_time == max(air_time))
flights %>% filter(!is.na(dep_time), !is.na(dep_delay), !is.na(arr_time), !is.na(arr_delay)) -> flights1
flights1
flights1 %>% filter(air_time == max(air_time))
flights1 %>% filter(air_time == max(air_time)) %>%  select(dest)
glimpse(flights)
#### Lecture 10/07/2020
- for any X and Y normally distributed random variables and any constants $\alpha$ and $\beta$, $\alpha X + \beta Y$ is a random variable which is also normally distributed
- linear combination of any normal random variables is normal
- we can treat random samples as a set of n objects, which are independent and randomly distributed
- define the sample mean as the average of observations, point estimator statistic
$$\mathbb{E}$$
